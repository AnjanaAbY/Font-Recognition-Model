{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ZVvkJP3XXBzjcQe3HJB_p_CtsYsoNWNG",
      "authorship_tag": "ABX9TyN0HGoTyVTwxSW0XsBH9MXs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnjanaAbY/Font-Recognition-Model/blob/main/Font_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_U3Cr8Sa8-e",
        "outputId": "57af1ceb-33ed-4460-ad09-1321ed8741ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 39 images belonging to 6 classes.\n",
            "Found 7 images belonging to 6 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 5s 721ms/step - loss: 2.2769 - accuracy: 0.1795\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 6s 1s/step - loss: 1.8803 - accuracy: 0.3077\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 4s 725ms/step - loss: 1.7865 - accuracy: 0.3333\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 6s 5s/step - loss: 1.2893 - accuracy: 0.4359\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 4s 3s/step - loss: 1.2737 - accuracy: 0.4872\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 4s 3s/step - loss: 1.1543 - accuracy: 0.5385\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 6s 5s/step - loss: 1.0660 - accuracy: 0.5897\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 4s 717ms/step - loss: 0.7110 - accuracy: 0.7436\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 5s 729ms/step - loss: 0.9632 - accuracy: 0.6410\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 4s 711ms/step - loss: 0.6805 - accuracy: 0.7436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "from keras.applications import VGG16 #pre-trained CNN model that is commonly used for image classification tasks\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create an ImageDataGenerator for data augmentation\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/font_patch',\n",
        "    target_size=(105, 105),\n",
        "    color_mode='rgb',\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training')\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/font_patch',\n",
        "    target_size=(105, 105),\n",
        "    color_mode='rgb',\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')\n",
        "\n",
        "# Load the pre-trained VGG16 model without the top (fully connected) layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(105, 105, 3))\n",
        "\n",
        "# Freeze the convolutional base\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create a new model on top\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(6, activation='softmax'))  # Assuming 6 font classes\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=2,  # Adjusted for the small dataset\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model.save('font_recognition_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Tesseract OCR\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idue6wKobPCb",
        "outputId": "312d245b-0e6b-4bb0-c29d-16e61e87f67a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 1s (4,834 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 121752 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for testing\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('font_recognition_model.h5')\n",
        "\n",
        "# Load and preprocess the new image\n",
        "img_path = '/content/raleway-regular-preview.png'\n",
        "img = image.load_img(img_path, target_size=(105, 105))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0) / 255.0  # Normalize the image\n",
        "img_array = np.vstack([img_array])\n",
        "\n",
        "# Make predictions for font detection\n",
        "predictions = model.predict(img_array)\n",
        "predicted_class_index = np.argmax(predictions, axis=1)[0]  # Get the predicted class index\n",
        "\n",
        "# Assuming font_names is a list where index corresponds to font class\n",
        "font_names = ['Lato', 'Raleway', 'Roboto', 'Sansation', 'Times New Roman', 'Walkway']\n",
        "\n",
        "# Get the predicted font name\n",
        "predicted_font_name = font_names[predicted_class_index]\n",
        "\n",
        "# Print the predicted font name\n",
        "print(\"Predicted Font Name:\", predicted_font_name)\n",
        "\n",
        "# Path to the Tesseract executable\n",
        "pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'\n",
        "\n",
        "# Load the image from your Colab environment\n",
        "img = Image.open(img_path)\n",
        "\n",
        "# Use pytesseract to extract text\n",
        "text = pytesseract.image_to_string(img)\n",
        "\n",
        "# Print the extracted text\n",
        "print(\"Extracted Text:\", text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XMJXCD-TW22",
        "outputId": "fd967d08-7b52-4437-a075-a50ee8345eb2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 253ms/step\n",
            "Predicted Font Name: Raleway\n",
            "Extracted Text: The quick brown fox jumps over the le\n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u75lSfVpb6f3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}